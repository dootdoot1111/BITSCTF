# Robots, devices, etc....

This challenge introduce us to the concept of robots.txt. robots.txt are text files often present on servers to help crawlers, crawl their site. They decide what pages should be allowed to the crawler for indexing.

Head over to the challenge site. Left click and choose 'Inspect element' to view the source html. Notice the comment:

